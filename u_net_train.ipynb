{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from typing import Optional, List, Tuple\n",
    "from multiprocessing import cpu_count, Pool\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from tsp_tinker_utils import TSPPackage, TSPProblem, TSPSolution, get_tsp_problem_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.getenv('DATA_PATH', './data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_tsp_problem(file_path: os.PathLike) -> Tuple[np.ndarray, List[int], float]:\n",
    "    with open(file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    packaged_problem = TSPPackage.from_json(json_data)\n",
    "    problem = packaged_problem.problem\n",
    "    best_solution = packaged_problem.best_solution\n",
    "\n",
    "    problems_and_solutions = (problem.city_connections_w_costs, best_solution.tour, best_solution.tot_cost)    \n",
    "    \n",
    "    return problems_and_solutions\n",
    "\n",
    "class TSPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_folder_path: os.PathLike, problem_size_lower_bound: Optional[int] = None, problem_size_upper_bound: Optional[int] = None, undirected_only: Optional[bool] = True, max_workers: int = cpu_count() - 1):\n",
    "        super(TSPDataset, self).__init__()\n",
    "        self.data = self.multi_threaded_load(data_folder_path, problem_size_lower_bound, problem_size_upper_bound, max_workers, undirected_only)\n",
    "\n",
    "    def multi_threaded_load(self, data_folder_path: os.PathLike, problem_size_lower_bound: Optional[int], problem_size_upper_bound: Optional[int], max_workers: int, undirected_only: Optional[bool] = True):\n",
    "        possible_folders = get_tsp_problem_folders(data_folder_path)\n",
    "        problem_file_paths = []\n",
    "        for _, problem_size, folder_path in possible_folders:\n",
    "            if (problem_size_lower_bound is None or problem_size >= problem_size_lower_bound) and (problem_size_upper_bound is None or problem_size <= problem_size_upper_bound):\n",
    "                # Add all files in the folder to the list of files to load\n",
    "                for file in os.listdir(folder_path):\n",
    "                    if file.endswith('.json'):\n",
    "                        problem_file_paths.append(os.path.join(folder_path, file))\n",
    "\n",
    "        formatted_data = []\n",
    "        with Pool(processes=max_workers) as worker_pool:\n",
    "            with tqdm(total=len(problem_file_paths), desc=\"Loading data from disk...\") as p_bar:\n",
    "                for result in worker_pool.imap_unordered(load_and_process_tsp_problem, problem_file_paths, chunksize=10):\n",
    "                    p_bar.update(1)\n",
    "                    formatted_data.append(result)\n",
    "\n",
    "        return formatted_data\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47022aeb4d394d33a9b1daa14e923b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading data from disk...:   0%|          | 0/254000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TSPDataset(DATA_PATH, problem_size_upper_bound=200)\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f5e34d6e7e455f904c3f9c7da3aa79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading data from disk...:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = TSPDataset(DATA_PATH, problem_size_lower_bound=201)\n",
    "print(len(validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_problem_and_tour_to_mse_problems(city_connections_w_costs: np.ndarray, tour: List[int]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    prob_size = city_connections_w_costs.shape[0]\n",
    "    current_path: np.ndarray = np.zeros((prob_size, prob_size))\n",
    "    previous_city  = 0\n",
    "\n",
    "    problems_with_context = []\n",
    "    targets = []\n",
    "    for i in range(len(tour)):\n",
    "        if i != 0:\n",
    "            current_city = tour[i]\n",
    "            current_path[previous_city, current_city] = 1\n",
    "            previous_city = current_city\n",
    "\n",
    "        problem_with_context = np.stack([city_connections_w_costs.copy(), current_path.copy()], axis=0)\n",
    "\n",
    "        next_city = 0\n",
    "        if i != len(tour) - 1:\n",
    "            next_city = tour[i + 1]\n",
    "\n",
    "        targets.append(next_city)\n",
    "        problems_with_context.append(problem_with_context)\n",
    "\n",
    "    batch = torch.tensor(np.array(problems_with_context), dtype=torch.float32)\n",
    "    targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    return batch, targets\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22, 2, 22, 22])\n",
      "torch.Size([22])\n"
     ]
    }
   ],
   "source": [
    "item_indx = len(train_dataset) - 23\n",
    "\n",
    "\n",
    "formatted_batch = convert_problem_and_tour_to_mse_problems(train_dataset[item_indx][0], train_dataset[item_indx][1])\n",
    "\n",
    "print(formatted_batch[0].shape)\n",
    "print(formatted_batch[1].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
