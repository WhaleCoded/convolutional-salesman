{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from data import TSPDataset, _normalize_np_array\n",
    "from config import Config, Checkpoint, MetaData, Metrics\n",
    "from model import ConvolutionalSalesmanNet, construct_path, calc_path_metric, calc_path_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = os.getenv(\"CONFIG_PATH\", \"./config.json\")\n",
    "\n",
    "if os.path.exists(CONFIG_PATH):\n",
    "    config = Config.from_json(CONFIG_PATH)\n",
    "else:\n",
    "    config = Config()\n",
    "    config.store_as_json(CONFIG_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc64f1d3de75406682112bcb8b987b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading data from disk...:   0%|          | 0/244000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 243950\n",
      "Validation dataset size: 50\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TSPDataset.from_disk(config.data_path, config.num_path_variations_per_example, problem_size_upper_bound=config.train_problem_size_cutoff)\n",
    "\n",
    "validation_uuids = config.get_validation_uuids()\n",
    "if validation_uuids is None:\n",
    "    validation_dataset = train_dataset.stratified_split(config.validation_tot_size)\n",
    "    validation_uuids = validation_dataset.get_uuids()\n",
    "    config.store_validation_uuids(validation_uuids)\n",
    "else:\n",
    "    validation_dataset = train_dataset.split_by_uuids(validation_uuids)\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(validation_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_checkpoint = config.get_curr_checkpoint()\n",
    "bssf_path_const_metric = config.get_bssf_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvolutionalSalesmanNet().to(config.device)\n",
    "loss_fn = nn.MSELoss().to(config.device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.min_lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=config.max_lr, total_steps=config.tot_train_batches)\n",
    "\n",
    "if curr_checkpoint is None:\n",
    "    curr_checkpoint = Checkpoint(\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        Metrics(),\n",
    "        MetaData()\n",
    "    )\n",
    "else:\n",
    "    print(\"Loading checkpoint state dicts\")\n",
    "    model.load_state_dict(curr_checkpoint.model_state_dict)\n",
    "    optimizer.load_state_dict(curr_checkpoint.optimizer_state_dict)\n",
    "    lr_scheduler.load_state_dict(curr_checkpoint.lr_scheduler_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6224e32aa344eeb0853b8973c4cf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/670000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43201fa9c36c42a18dacecf3e9eb59ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0')\n",
      "tensor([[-1.0000,  0.7651,  0.1905,  ...,  0.1621,  0.7027,  0.2395],\n",
      "        [-1.0000, -1.0000,  0.4092,  ...,  0.3328, -0.4240, -0.3035],\n",
      "        [-1.0000, -1.0000, -1.0000,  ...,  0.2304,  0.2397,  0.1950],\n",
      "        ...,\n",
      "        [-1.0000, -1.0000, -1.0000,  ..., -1.0000,  0.0509,  0.2659],\n",
      "        [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -0.1391],\n",
      "        [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "-0.8878732209117058\n",
      "[-0.8878732209117058]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m curr_checkpoint\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mnum_batches_trained \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     36\u001b[0m master_p_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m curr_checkpoint_tot_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m curr_checkpoint\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mnum_batches_trained \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Update postfix\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     num_batches_before_checkpoint \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mbatches_per_checkpoint \u001b[38;5;241m%\u001b[39m curr_checkpoint\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mnum_batches_trained\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader)\n",
    "master_p_bar = tqdm(range(config.tot_train_batches), desc=\"Training\")\n",
    "master_p_bar.update(curr_checkpoint.metadata.num_batches_trained)\n",
    "model.train()\n",
    "\n",
    "try:\n",
    "    curr_checkpoint_tot_loss = 0\n",
    "    while curr_checkpoint.metadata.num_batches_trained < config.tot_train_batches:\n",
    "        master_p_bar.set_description(\"Training\")\n",
    "        batch: torch.Tensor\n",
    "        target: torch.Tensor\n",
    "\n",
    "        try:\n",
    "            (batch, target) = next(train_iter)\n",
    "        except StopIteration:\n",
    "            train_iter = iter(train_loader)\n",
    "            (batch, target) = next(train_iter)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Format the data and move to GPU\n",
    "        batch = batch.squeeze(0).to(config.device)\n",
    "        target = target.squeeze(0).to(config.device)\n",
    "\n",
    "        # Predict and Calculate Loss\n",
    "        path_predictions: torch.Tensor = model(batch)\n",
    "        loss: torch.Tensor = loss_fn(path_predictions, target)\n",
    "\n",
    "        # Adjust Model\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # Update Progress\n",
    "        curr_checkpoint.metadata.num_batches_trained += 1\n",
    "        master_p_bar.update(1)\n",
    "        curr_checkpoint_tot_loss += loss.item()\n",
    "\n",
    "        if curr_checkpoint.metadata.num_batches_trained % 100 == 0:\n",
    "            # Update postfix\n",
    "            num_batches_before_checkpoint = config.batches_per_checkpoint % curr_checkpoint.metadata.num_batches_trained\n",
    "            trained_batches = config.batches_per_checkpoint - num_batches_before_checkpoint\n",
    "            master_p_bar.set_postfix(\n",
    "                train_loss= curr_checkpoint_tot_loss/ trained_batches if trained_batches > 0 else 1, \n",
    "                vald_loss = curr_checkpoint.metrics.validation_loss[-1] if len(curr_checkpoint.metrics.validation_loss) > 0 else None,\n",
    "                path_construction_metric = curr_checkpoint.metrics.path_construction_metrics[-1] if len(curr_checkpoint.metrics.path_construction_metrics) > 0 else None)\n",
    "\n",
    "        if curr_checkpoint.metadata.num_batches_trained % config.batches_per_checkpoint == 0:\n",
    "            optimizer.zero_grad()\n",
    "            master_p_bar.set_description(\"Validating\")\n",
    "            # Run Validation and Save Checkpoint\n",
    "            curr_checkpoint.metrics.training_loss.append(curr_checkpoint_tot_loss / config.batches_per_checkpoint)\n",
    "            curr_checkpoint_tot_loss = 0\n",
    "\n",
    "            model.eval()\n",
    "            tot_validation_loss = 0\n",
    "            path_construction_metric = []\n",
    "            for (batch, target) in tqdm(validation_loader):\n",
    "                batch = batch.squeeze(0).to(config.device)\n",
    "                target = target.squeeze(0).to(config.device)\n",
    "\n",
    "                path_predictions = model(batch)\n",
    "                loss = loss_fn(path_predictions, target)\n",
    "\n",
    "                tot_validation_loss += loss.item()\n",
    "\n",
    "                constructed_path = construct_path(model, batch[0, 0])\n",
    "                path_metric = calc_path_metric(constructed_path, target[0], batch[0, 0])\n",
    "                path_construction_metric.append(path_metric)\n",
    "\n",
    "                break\n",
    "\n",
    "            curr_checkpoint.metrics.validation_loss.append(tot_validation_loss / len(validation_loader))\n",
    "            print(path_construction_metric)\n",
    "            checkpoint_path_construction_average = np.mean(path_construction_metric)\n",
    "            curr_checkpoint.metrics.path_construction_metrics.append(checkpoint_path_construction_average)\n",
    "            curr_checkpoint.metrics.learning_rate.append(lr_scheduler.get_last_lr())\n",
    "\n",
    "            # Update postfix\n",
    "            num_batches_before_checkpoint = config.batches_per_checkpoint % curr_checkpoint.metadata.num_batches_trained\n",
    "            trained_batches = config.batches_per_checkpoint - num_batches_before_checkpoint\n",
    "            master_p_bar.set_postfix(train_loss= curr_checkpoint.metrics.training_loss[-1], \n",
    "                                     vald_loss = curr_checkpoint.metrics.validation_loss[-1],\n",
    "                                     path_construction_metric = curr_checkpoint.metrics.path_construction_metrics[-1])\n",
    "\n",
    "\n",
    "            if bssf_path_const_metric is None or checkpoint_path_construction_average < bssf_path_const_metric:\n",
    "                bssf_bssf_path_const_metric = checkpoint_path_construction_average\n",
    "                config.store_new_bssf(model, curr_checkpoint.metrics)\n",
    "\n",
    "            # Get new state dicts\n",
    "            curr_checkpoint.model_state_dict = model.state_dict()\n",
    "            curr_checkpoint.optimizer_state_dict = optimizer.state_dict()\n",
    "            curr_checkpoint.lr_scheduler_state_dict = lr_scheduler.state_dict()\n",
    "            config.store_new_checkpoint(curr_checkpoint)\n",
    "            model.train()\n",
    "\n",
    "except Exception as e:\n",
    "    print(batch.shape)\n",
    "    print(e)\n",
    "\n",
    "    # Dang memory leaks\n",
    "    del model\n",
    "\n",
    "    raise e\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = TSPDataset(DATA_PATH, problem_size_lower_bound=TEST_PROBLEM_SIZE_CUTOFF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
